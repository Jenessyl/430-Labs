{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a4cbb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Word List ===\n",
      "\n",
      "Downloading NLTK words corpus...\n",
      "Loaded 9972 five-letter words from NLTK\n",
      "Sample words: ['AALII', 'AARON', 'ABACA', 'ABACK', 'ABAFF', 'ABAFT', 'ABAMA', 'ABASE', 'ABASH', 'ABASK']\n",
      "\n",
      "=== Wordle Feedback Mechanism ===\n",
      "\n",
      "Guess: ROBOT\n",
      "Answer: FLOOR\n",
      "Pattern: ðŸŸ¨ðŸŸ¨â¬œðŸŸ©â¬œ (1, 1, 0, 2, 0)\n",
      "\n",
      "Guess: CRANE\n",
      "Answer: REACT\n",
      "Pattern: ðŸŸ¨ðŸŸ¨ðŸŸ©â¬œðŸŸ¨ (1, 1, 2, 0, 1)\n",
      "\n",
      "Guess: SALET\n",
      "Answer: LASER\n",
      "Pattern: ðŸŸ¨ðŸŸ©ðŸŸ¨ðŸŸ©â¬œ (1, 2, 1, 2, 0)\n",
      "\n",
      "=== Constraint Propagation Example ===\n",
      "\n",
      "Sample from 9972 total words: ['FLACK', 'FLAFF', 'FLAIL', 'FLAIR', 'FLAKE', 'FLAKY', 'FLAMB', 'FLAME']\n",
      "After guessing 'CRANE' with answer 'FLACK':\n",
      "Pattern: (1, 0, 2, 0, 0)\n",
      "Remaining possibilities: ['FLACK']\n",
      "Eliminated: {'FLAIL', 'FLAKY', 'FLAFF', 'FLAME', 'FLAMB', 'FLAIR', 'FLAKE'}\n",
      "\n",
      "From full word list, 49 words remain\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_wordle_pattern(guess, answer):\n",
    "    \"\"\"\n",
    "    Generate Wordle feedback pattern.\n",
    "    Returns tuple: 0=gray (not in word), 1=yellow (wrong position), 2=green (correct)\n",
    "    \"\"\"\n",
    "    result = [0] * 5\n",
    "    answer_counts = Counter(answer)\n",
    "    \n",
    "    # First pass: mark all exact matches (green)\n",
    "    for i, (g, a) in enumerate(zip(guess, answer)):\n",
    "        if g == a:\n",
    "            result[i] = 2\n",
    "            answer_counts[g] -= 1  # Consume this letter\n",
    "    \n",
    "    # Second pass: mark letters in wrong positions (yellow)\n",
    "    for i, g in enumerate(guess):\n",
    "        if result[i] == 0 and answer_counts[g] > 0:\n",
    "            result[i] = 1\n",
    "            answer_counts[g] -= 1  # Consume this letter\n",
    "    \n",
    "    return tuple(result)\n",
    "\n",
    "def apply_constraints(word, guess, pattern):\n",
    "    \"\"\"Check if a word is consistent with observed guess/pattern\"\"\"\n",
    "    return get_wordle_pattern(guess, word) == pattern\n",
    "\n",
    "# Load word list from NLTK\n",
    "print(\"=== Loading Word List ===\\n\")\n",
    "\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.corpus import words\n",
    "    \n",
    "    # Download if not already present\n",
    "    try:\n",
    "        words.words()\n",
    "    except LookupError:\n",
    "        print(\"Downloading NLTK words corpus...\")\n",
    "        nltk.download('words', quiet=True)\n",
    "    \n",
    "    # Get all 5-letter words, uppercase\n",
    "    all_words = words.words()\n",
    "    WORD_LIST = sorted(set(word.upper() for word in all_words if len(word) == 5 and word.isalpha()))\n",
    "    \n",
    "    print(f\"Loaded {len(WORD_LIST)} five-letter words from NLTK\")\n",
    "    print(f\"Sample words: {WORD_LIST[:10]}\")\n",
    "    print()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"NLTK not installed. Using fallback word list.\")\n",
    "    # Fallback to a larger curated list\n",
    "    WORD_LIST = [\"SALET\", \"ROATE\", \"RAISE\", \"ARISE\", \"IRATE\", \"CRANE\", \"SLATE\", \n",
    "                 \"CRATE\", \"TRACE\", \"STARE\", \"ADORE\", \"ALONE\", \"ATONE\", \"STORE\",\n",
    "                 \"SHORE\", \"SNORE\", \"SPORE\", \"SCORE\", \"SWORE\", \"SHONE\", \"STONE\",\n",
    "                 \"DRONE\", \"PRONE\", \"OZONE\", \"PHONE\", \"THOSE\", \"WHOSE\", \"CHOSE\",\n",
    "                 \"BRAKE\", \"FLAKE\", \"SHAKE\", \"SNAKE\", \"QUAKE\", \"AWAKE\"]\n",
    "    print(f\"Using fallback list: {len(WORD_LIST)} words\\n\")\n",
    "\n",
    "# Demonstration\n",
    "print(\"=== Wordle Feedback Mechanism ===\\n\")\n",
    "\n",
    "test_cases = [\n",
    "    (\"ROBOT\", \"FLOOR\"),  # Repeated letters\n",
    "    (\"CRANE\", \"REACT\"),  # Anagrams\n",
    "    (\"SALET\", \"LASER\"),  # Close match\n",
    "]\n",
    "\n",
    "for guess, answer in test_cases:\n",
    "    pattern = get_wordle_pattern(guess, answer)\n",
    "    pattern_str = ''.join(['â¬œ' if p == 0 else 'ðŸŸ¨' if p == 1 else 'ðŸŸ©' for p in pattern])\n",
    "    print(f\"Guess: {guess}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(f\"Pattern: {pattern_str} {pattern}\")\n",
    "    print()\n",
    "\n",
    "# Show constraint propagation with realistic word list\n",
    "print(\"=== Constraint Propagation Example ===\\n\")\n",
    "# Select words starting with 'FL' from full list\n",
    "sample_words = [w for w in WORD_LIST if w.startswith('FL')][:8]\n",
    "if len(sample_words) < 5:\n",
    "    sample_words = WORD_LIST[:8]\n",
    "\n",
    "guess = \"CRANE\"\n",
    "answer = sample_words[0] if sample_words else \"FLOUR\"\n",
    "pattern = get_wordle_pattern(guess, answer)\n",
    "\n",
    "print(f\"Sample from {len(WORD_LIST)} total words: {sample_words}\")\n",
    "print(f\"After guessing '{guess}' with answer '{answer}':\")\n",
    "print(f\"Pattern: {pattern}\")\n",
    "remaining = [w for w in sample_words if apply_constraints(w, guess, pattern)]\n",
    "print(f\"Remaining possibilities: {remaining}\")\n",
    "print(f\"Eliminated: {set(sample_words) - set(remaining)}\")\n",
    "print(f\"\\nFrom full word list, {len([w for w in WORD_LIST if apply_constraints(w, guess, pattern)])} words remain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f786c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Frequency-Based Heuristic Agent ===\n",
      "\n",
      "Total word list size: 9972\n",
      "\n",
      "Testing on random words: ['CIDER', 'AMPLY', 'KETCH']\n",
      "\n",
      "Target word: CIDER\n",
      "Attempt 1: SAITE -> â¬œâ¬œðŸŸ¨â¬œðŸŸ¨\n",
      "  Remaining words: 9972\n",
      "Attempt 2: FINER -> â¬œðŸŸ©â¬œðŸŸ©ðŸŸ©\n",
      "  Remaining words: 259\n",
      "Attempt 3: HIVER -> â¬œðŸŸ©â¬œðŸŸ©ðŸŸ©\n",
      "  Remaining words: 39\n",
      "Attempt 4: MIDER -> â¬œðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©\n",
      "  Remaining words: 26\n",
      "Attempt 5: CIDER -> ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©\n",
      "  Remaining words: 4\n",
      "âœ“ Solved in 5 guesses!\n",
      "\n",
      "\n",
      "Target word: AMPLY\n",
      "Attempt 1: SAITE -> â¬œðŸŸ¨â¬œâ¬œâ¬œ\n",
      "  Remaining words: 9972\n",
      "Attempt 2: CORAL -> â¬œâ¬œâ¬œðŸŸ¨ðŸŸ¨\n",
      "  Remaining words: 822\n",
      "Attempt 3: PLAGA -> ðŸŸ¨ðŸŸ¨ðŸŸ¨â¬œâ¬œ\n",
      "  Remaining words: 68\n",
      "Attempt 4: AMPLY -> ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©\n",
      "  Remaining words: 2\n",
      "âœ“ Solved in 4 guesses!\n",
      "\n",
      "\n",
      "Target word: KETCH\n",
      "Attempt 1: SAITE -> â¬œâ¬œâ¬œðŸŸ¨ðŸŸ¨\n",
      "  Remaining words: 9972\n",
      "Attempt 2: TENET -> ðŸŸ¨ðŸŸ©â¬œâ¬œâ¬œ\n",
      "  Remaining words: 226\n",
      "Attempt 3: KETCH -> ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©\n",
      "  Remaining words: 15\n",
      "âœ“ Solved in 3 guesses!\n",
      "\n",
      "\n",
      "=== Analysis: Best Opening Words by Frequency ===\n",
      "\n",
      "Top 10 words by frequency score:\n",
      " 1. SAITE: 11550.32 (5 unique letters)\n",
      " 2. BARIE: 11485.51 (5 unique letters)\n",
      " 3. SAIRY: 11444.94 (5 unique letters)\n",
      " 4. SAILY: 11406.75 (5 unique letters)\n",
      " 5. TARIE: 11394.29 (5 unique letters)\n",
      " 6. SADIE: 11375.84 (5 unique letters)\n",
      " 7. MANEY: 11333.20 (5 unique letters)\n",
      " 8. COREY: 11297.09 (5 unique letters)\n",
      " 9. SOREE: 11276.65 (4 unique letters)\n",
      "10. SOLAY: 11252.80 (5 unique letters)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Letter frequency data from Wikipedia (English text)\n",
    "# https://en.wikipedia.org/wiki/Letter_frequency\n",
    "LETTER_FREQUENCIES = {\n",
    "    'E': 12.70, 'T': 9.06, 'A': 8.17, 'O': 7.51, 'I': 6.97,\n",
    "    'N': 6.75, 'S': 6.33, 'H': 6.09, 'R': 5.99, 'D': 4.25,\n",
    "    'L': 4.03, 'C': 2.78, 'U': 2.76, 'M': 2.41, 'W': 2.36,\n",
    "    'F': 2.23, 'G': 2.02, 'Y': 1.97, 'P': 1.93, 'B': 1.29,\n",
    "    'V': 0.98, 'K': 0.77, 'J': 0.15, 'X': 0.15, 'Q': 0.10,\n",
    "    'Z': 0.07\n",
    "}\n",
    "\n",
    "def build_frequency_tables(words):\n",
    "    \"\"\"Calculate letter frequencies by position from word list\"\"\"\n",
    "    position_freq = [defaultdict(int) for _ in range(5)]\n",
    "    \n",
    "    for word in words:\n",
    "        for i, letter in enumerate(word):\n",
    "            position_freq[i][letter] += 1\n",
    "    \n",
    "    return position_freq\n",
    "\n",
    "def score_word_frequency(word, freq_tables, remaining_words):\n",
    "    \"\"\"Score word based on letter/position frequencies\"\"\"\n",
    "    # Use position-specific frequencies from the remaining words\n",
    "    score = sum(freq_tables[i][letter] for i, letter in enumerate(word))\n",
    "    \n",
    "    # Bonus for unique letters (more information gathered)\n",
    "    unique_ratio = len(set(word)) / len(word)\n",
    "    score *= (1 + unique_ratio)\n",
    "    \n",
    "    # Add bonus based on general English letter frequency\n",
    "    english_freq_score = sum(LETTER_FREQUENCIES.get(letter, 0) for letter in set(word))\n",
    "    score += english_freq_score * 0.1  # Small weight for general frequency\n",
    "    \n",
    "    return score\n",
    "\n",
    "def frequency_agent_solve(answer, word_list, verbose=True):\n",
    "    \"\"\"Solve Wordle using frequency heuristics\"\"\"\n",
    "    remaining = word_list.copy()\n",
    "    guesses = []\n",
    "    \n",
    "    for attempt in range(6):\n",
    "        freq_tables = build_frequency_tables(remaining)\n",
    "        \n",
    "        # Choose word with highest frequency score from remaining possibilities\n",
    "        best_word = max(remaining, key=lambda w: score_word_frequency(w, freq_tables, remaining))\n",
    "        guesses.append(best_word)\n",
    "        \n",
    "        pattern = get_wordle_pattern(best_word, answer)\n",
    "        \n",
    "        if verbose:\n",
    "            pattern_str = ''.join(['â¬œ' if p == 0 else 'ðŸŸ¨' if p == 1 else 'ðŸŸ©' for p in pattern])\n",
    "            print(f\"Attempt {attempt + 1}: {best_word} -> {pattern_str}\")\n",
    "            print(f\"  Remaining words: {len(remaining)}\")\n",
    "        \n",
    "        if best_word == answer:\n",
    "            if verbose:\n",
    "                print(f\"âœ“ Solved in {len(guesses)} guesses!\\n\")\n",
    "            return guesses\n",
    "        \n",
    "        # Update remaining words based on constraints\n",
    "        remaining = [w for w in remaining if apply_constraints(w, best_word, pattern)]\n",
    "        \n",
    "        if not remaining:\n",
    "            if verbose:\n",
    "                print(f\"âœ— No valid words remain! Answer was {answer}\\n\")\n",
    "            return guesses\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"âœ— Failed to solve in 6 guesses. Answer was {answer}\\n\")\n",
    "    return guesses\n",
    "\n",
    "# Test the frequency agent\n",
    "print(\"=== Frequency-Based Heuristic Agent ===\\n\")\n",
    "print(f\"Total word list size: {len(WORD_LIST)}\\n\")\n",
    "\n",
    "# Select diverse test words\n",
    "import random\n",
    "random.seed(42)\n",
    "test_answers = random.sample(WORD_LIST, 3)\n",
    "\n",
    "print(f\"Testing on random words: {test_answers}\\n\")\n",
    "\n",
    "for answer in test_answers:\n",
    "    print(f\"Target word: {answer}\")\n",
    "    result = frequency_agent_solve(answer, WORD_LIST)\n",
    "    print()\n",
    "\n",
    "# Show top words by frequency\n",
    "print(\"=== Analysis: Best Opening Words by Frequency ===\\n\")\n",
    "freq_tables = build_frequency_tables(WORD_LIST)\n",
    "all_scores = [(w, score_word_frequency(w, freq_tables, WORD_LIST)) for w in WORD_LIST]\n",
    "all_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 10 words by frequency score:\")\n",
    "for i, (word, score) in enumerate(all_scores[:10], 1):\n",
    "    unique_letters = len(set(word))\n",
    "    print(f\"{i:2}. {word}: {score:.2f} ({unique_letters} unique letters)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "235d40ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Information Theory (Entropy) Agent ===\n",
      "\n",
      "Testing on: ['CIDER', 'AMPLY', 'KETCH']\n",
      "\n",
      "Target word: CIDER\n",
      "Attempt 1: SERAI -> â¬œðŸŸ¨ðŸŸ¨â¬œðŸŸ¨\n",
      "  Entropy: 5.89 bits\n",
      "  Remaining words: 9972\n",
      "Attempt 2: DITER -> ðŸŸ¨ðŸŸ©â¬œðŸŸ©ðŸŸ©\n",
      "  Entropy: 3.74 bits\n",
      "  Remaining words: 165\n",
      "Attempt 3: BIDER -> â¬œðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©\n",
      "  Entropy: 0.65 bits\n",
      "  Remaining words: 6\n",
      "Attempt 4: CIDER -> ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©\n",
      "  Entropy: 0.72 bits\n",
      "  Remaining words: 5\n",
      "âœ“ Solved in 4 guesses!\n",
      "\n",
      "\n",
      "Target word: AMPLY\n",
      "Attempt 1: TERAS -> â¬œâ¬œâ¬œðŸŸ¨â¬œ\n",
      "  Entropy: 5.83 bits\n",
      "  Remaining words: 9972\n",
      "Attempt 2: MANIA -> ðŸŸ¨ðŸŸ¨â¬œâ¬œâ¬œ\n",
      "  Entropy: 5.45 bits\n",
      "  Remaining words: 950\n",
      "Attempt 3: ALBUM -> ðŸŸ©ðŸŸ¨â¬œâ¬œðŸŸ¨\n",
      "  Entropy: 3.88 bits\n",
      "  Remaining words: 23\n",
      "Attempt 4: AMPLY -> ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©\n",
      "  Entropy: 1.00 bits\n",
      "  Remaining words: 2\n",
      "âœ“ Solved in 4 guesses!\n",
      "\n",
      "\n",
      "Target word: KETCH\n",
      "Attempt 1: SINAE -> â¬œâ¬œâ¬œâ¬œðŸŸ¨\n",
      "  Entropy: 5.86 bits\n",
      "  Remaining words: 9972\n",
      "Attempt 2: RELET -> â¬œðŸŸ©â¬œâ¬œðŸŸ¨\n",
      "  Entropy: 5.63 bits\n",
      "  Remaining words: 699\n",
      "Attempt 3: HETTY -> ðŸŸ¨ðŸŸ©ðŸŸ©â¬œâ¬œ\n",
      "  Entropy: 3.35 bits\n",
      "  Remaining words: 20\n",
      "Attempt 4: FETCH -> â¬œðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©\n",
      "  Entropy: 0.92 bits\n",
      "  Remaining words: 3\n",
      "Attempt 5: KETCH -> ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©\n",
      "  Entropy: 1.00 bits\n",
      "  Remaining words: 2\n",
      "âœ“ Solved in 5 guesses!\n",
      "\n",
      "\n",
      "=== First Guess Comparison ===\n",
      "\n",
      "Calculating best opening words (sampling for efficiency)...\n",
      "\n",
      "Top 5 words by frequency score:\n",
      "  SOLAY: 11252.80\n",
      "  LANEY: 11089.36\n",
      "  CARET: 10997.87\n",
      "  CARTY: 10578.80\n",
      "  MONEY: 10459.13\n",
      "\n",
      "Top 5 words by entropy:\n",
      "  ARIES: 5.81 bits\n",
      "  RATEL: 5.73 bits\n",
      "  CARET: 5.72 bits\n",
      "  ARLES: 5.72 bits\n",
      "  SIENA: 5.69 bits\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def calculate_pattern_entropy(word, possible_words):\n",
    "    \"\"\"\n",
    "    Calculate expected information gain (entropy) for a guess.\n",
    "    Higher entropy = more expected information gained.\n",
    "    \"\"\"\n",
    "    if not possible_words:\n",
    "        return 0\n",
    "    \n",
    "    # Count how many words produce each pattern\n",
    "    pattern_counts = {}\n",
    "    for candidate in possible_words:\n",
    "        pattern = get_wordle_pattern(word, candidate)\n",
    "        pattern_counts[pattern] = pattern_counts.get(pattern, 0) + 1\n",
    "    \n",
    "    # Calculate entropy: -sum(p * log2(p))\n",
    "    total = len(possible_words)\n",
    "    entropy = 0\n",
    "    for count in pattern_counts.values():\n",
    "        if count > 0:\n",
    "            probability = count / total\n",
    "            entropy -= probability * math.log2(probability)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def entropy_agent_solve(answer, word_list, verbose=True):\n",
    "    \"\"\"Solve Wordle using information theory (entropy maximization)\"\"\"\n",
    "    remaining = word_list.copy()\n",
    "    guesses = []\n",
    "    \n",
    "    for attempt in range(6):\n",
    "        # For first guess, we can pre-compute on full list\n",
    "        # For subsequent guesses, only consider remaining words for efficiency\n",
    "        if attempt == 0 and len(remaining) > 1000:\n",
    "            # Sample for efficiency on first guess with large word list\n",
    "            sample_size = min(2000, len(remaining))\n",
    "            candidates = random.sample(remaining, sample_size)\n",
    "        else:\n",
    "            candidates = remaining\n",
    "        \n",
    "        # Calculate entropy for candidate guesses\n",
    "        word_scores = [(w, calculate_pattern_entropy(w, remaining)) for w in candidates]\n",
    "        word_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        best_word = word_scores[0][0]\n",
    "        best_entropy = word_scores[0][1]\n",
    "        guesses.append(best_word)\n",
    "        \n",
    "        pattern = get_wordle_pattern(best_word, answer)\n",
    "        \n",
    "        if verbose:\n",
    "            pattern_str = ''.join(['â¬œ' if p == 0 else 'ðŸŸ¨' if p == 1 else 'ðŸŸ©' for p in pattern])\n",
    "            print(f\"Attempt {attempt + 1}: {best_word} -> {pattern_str}\")\n",
    "            print(f\"  Entropy: {best_entropy:.2f} bits\")\n",
    "            print(f\"  Remaining words: {len(remaining)}\")\n",
    "        \n",
    "        if best_word == answer:\n",
    "            if verbose:\n",
    "                print(f\"âœ“ Solved in {len(guesses)} guesses!\\n\")\n",
    "            return guesses\n",
    "        \n",
    "        remaining = [w for w in remaining if apply_constraints(w, best_word, pattern)]\n",
    "        \n",
    "        if not remaining:\n",
    "            if verbose:\n",
    "                print(f\"âœ— No valid words remain! Answer was {answer}\\n\")\n",
    "            return guesses\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"âœ— Failed to solve in 6 guesses. Answer was {answer}\\n\")\n",
    "    return guesses\n",
    "\n",
    "# Test the entropy agent\n",
    "print(\"=== Information Theory (Entropy) Agent ===\\n\")\n",
    "\n",
    "# Use same test words for comparison\n",
    "random.seed(42)\n",
    "test_answers = random.sample(WORD_LIST, 3)\n",
    "\n",
    "print(f\"Testing on: {test_answers}\\n\")\n",
    "\n",
    "for answer in test_answers:\n",
    "    print(f\"Target word: {answer}\")\n",
    "    result = entropy_agent_solve(answer, WORD_LIST)\n",
    "    print()\n",
    "\n",
    "# Compare first guesses\n",
    "print(\"=== First Guess Comparison ===\\n\")\n",
    "\n",
    "# Sample words for entropy calculation (full list too slow)\n",
    "print(\"Calculating best opening words (sampling for efficiency)...\\n\")\n",
    "sample_words = random.sample(WORD_LIST, min(1000, len(WORD_LIST)))\n",
    "\n",
    "print(\"Top 5 words by frequency score:\")\n",
    "freq_tables = build_frequency_tables(WORD_LIST)\n",
    "freq_scores = [(w, score_word_frequency(w, freq_tables, WORD_LIST)) for w in sample_words]\n",
    "freq_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "for word, score in freq_scores[:5]:\n",
    "    print(f\"  {word}: {score:.2f}\")\n",
    "\n",
    "print(\"\\nTop 5 words by entropy:\")\n",
    "entropy_scores = [(w, calculate_pattern_entropy(w, WORD_LIST)) for w in sample_words]\n",
    "entropy_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "for word, entropy in entropy_scores[:5]:\n",
    "    print(f\"  {word}: {entropy:.2f} bits\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
